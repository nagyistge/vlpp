#!/usr/bin/env python
# -*- coding: utf-8 -*-


import argparse
from datetime import datetime
import os
import shutil
import sys

from vlpp.lib import utils
from vlpp.vlpp import App


def get_arguments():

    parser = argparse.ArgumentParser(
            formatter_class=argparse.RawDescriptionHelpFormatter,
            description="""
            Documentation at https://github.com/villeneuvelab/vlpp
            Please report any issues there
            """,
            epilog="""
            "Pas de problème, où est le manuel ?"
            """)

    parser.add_argument(
            '-p', '--pet_dir',
            required=True,
            help='Directory with your PET dataset for one participant. By default, the pipeline will select all the ".nii.gz" files inside the directory. To change this behaviour, change the value of ["selectfiles"]["pet"] inside your configuration file.'
            )

    parser.add_argument(
            '-i', '--participant_id',
            required=False,
            help='Participant identification. By default, it will be the PET directory name.'
            )

    parser.add_argument(
            '-f', '--fs_dir',
            required=False,
            help='Directory with the freesurfer pipeline of the participant. If no fs_dir is provided by the user, the script guesses that fs_dir is a directory named "freesurfer" inside pet_dir.'
            )

    parser.add_argument(
            '-c', '--config_file',
            required=False,
            help='Path to a json configuration file. The pipeline configures itself by looking into several files. First, it looks into the default file inside the installation directory (vlpp/config/config_default.json). Then, if the file exists, it looks inside the current directory in "code/config.json". Finally it looks to the file given with this option.',
            )

    parser.add_argument(
            '-o', '--output_dir',
            required=False,
            help='Output directory. By default, this is the current directory.'
            )

    return parser.parse_args()


def main():

    # Main workflow
    app = App(get_arguments())
    wf = app.wf

    # Graph
    #graph2use: 'orig', 'hierarchical' (default), 'flat', 'exec', 'colored'
    wf.write_graph(graph2use='colored')

    # Run
    now = datetime.now().strftime("%y%m%d-%H%M%S")
    wf.run()

    '''
    config_run = {
            "plugin": "SGEGraph",
            "plugin_args": {
                "qsub_args": "-l procs=12 -l walltime=1:00:00 -A yai-974-aa"
                }
            }
    wf.run(plugin=PLUGIN_NAME, plugin_args=ARGS_DICT)
    wf.run(**config_run)
    '''

    # Cleaning
    output_dir = app.config_dict['arguments']['output_dir']
    log_dir = os.path.join(output_dir, "log")
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    #pypeline.log
    shutil.move(
            os.path.join(output_dir, "pypeline.log"),
            os.path.join(log_dir, "pypeline-{}.log".format(now))
            )

    #pypeline.lock
    os.remove(os.path.join(output_dir, "pypeline.lock"))

    #graph
    graph_file = os.path.join(
            app.config_dict['arguments']['working_dir'],
            utils.PIPELINENAME, 'graph.dot.png')
    shutil.copy2(
            graph_file, os.path.join(log_dir, 'graph-{}.dot.png'.format(now)))

    #config
    utils.write_json(
            app.config_dict,
            os.path.join(log_dir, "config-{}.json".format(now))
            )

    '''
    import subprocess
    try:
        wf.run()
    finally:
        shutil.rmtree(tmpDir, ignore_errors=True)
        suprocess.call( ['rsync', '-a', myscratch, myhome])
        shutil.rmtree(myscratch)
    '''

    return 0


if __name__ == '__main__':
    sys.exit(main())

